# Muesli

## Overview

Muesli is a new DRL algorithm that extends Maximum a-posteriori Policy Optimization (MPO) and is inspired by MuZero.
It has an auxiliary prediction head that predicts the reward, value, and policy logits several time steps in the future.


Original paper: 

* [Muesli](https://arxiv.org/abs/2104.06159)

Reference resources:

* [Safe and efficient off-policy reinforcement learning](https://arxiv.org/abs/1606.02647)
* [Observe and Look Further:
Achieving Consistent Performance on Atari](https://arxiv.org/abs/1805.11593)
* [Mastering Atari, Go, Chess and Shogi by Planning with a
Learned Model](https://arxiv.org/abs/1911.08265)
* [IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures](https://arxiv.org/abs/1802.01561)
* [The Reactor: A Fast and Sample-Efficient Actor-Critic Agent for Reinforcement Learning](https://openreview.net/pdf?id=rkHVZWZAZ)

TODO: Add results
